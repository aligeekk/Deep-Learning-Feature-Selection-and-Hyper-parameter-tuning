{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv1D, MaxPooling1D, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import normalize, to_categorical\n",
    "from keras import optimizers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings \n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python generator which takes X, y and batch_size as parameters and returns batches of X and y \n",
    "def gen(X, y, batch_size = 8):\n",
    "    i = 0\n",
    "    while True:\n",
    "        X_b = []\n",
    "        y_b = []\n",
    "        for b in range(batch_size):\n",
    "            if i == len(X)-1:\n",
    "                 i = 0\n",
    "            X_b_i = X[i]\n",
    "            y_b_i = y[i]\n",
    "            i = i + 1\n",
    "            X_b.append(X_b_i)\n",
    "            y_b.append(y_b_i)\n",
    "\n",
    "        yield np.asarray(X_b), np.asarray(y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# reading the data\n",
    "fname = '../input/dlproject.csv'\n",
    "df = pd.read_csv(fname, sep = ',')\n",
    "features = np.array(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading pandas dataframe into numpy, X = features, y = labels\n",
    "data = df.values\n",
    "X = data[: , :-1]\n",
    "y = data[: , -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranking feature importances based on extra tree classifier\n",
    "forest = ExtraTreesClassifier(n_estimators=100, random_state=78)\n",
    "forest.fit(X, y)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using only 16 most important features\n",
    "X1 = data[: , indices[0]].reshape(-1, 1)\n",
    "for i in range(1, 16):\n",
    "    X1 = np.hstack((X1, data[:, indices[i]].reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the labels to categorical because the dataset we are using has 9 classes\n",
    "y = to_categorical(y, num_classes = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the features\n",
    "X1 = normalize(X1, order = 2, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting the data into training, cross-validation and test sets\n",
    "X_train, X_cvtest, y_train, y_cvtest = train_test_split(X1, y, test_size = 0.5, random_state = 78, stratify = y)\n",
    "X_cv, X_test, y_cv, y_test = train_test_split(X_cvtest, y_cvtest, test_size = 0.5, random_state = 78, stratify = y_cvtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_cv.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size and epochs for models without hyper-parameter tuning\n",
    "batch_size = 128\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-layer neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(9, activation='softmax', input_shape=(16,)))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "model.fit_generator(gen(X_train, y_train, batch_size), \n",
    "                    steps_per_epoch = len(X_train)/batch_size, \n",
    "                    nb_epoch = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate_generator(gen(X_test, y_test, batch_size), \n",
    "                                               steps = len(X_test)/batch_size)\n",
    "print(\"Accuracy score with 1 layer:\", test_acc)\n",
    "print(\"Loss with 1 layer:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-layer neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(9,input_shape=(16,),activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(6,activation='relu'))\n",
    "model.add(Dense(9,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.fit_generator(gen(X_train, y_train, batch_size), \n",
    "                    steps_per_epoch = len(X_train)/batch_size, \n",
    "                    nb_epoch = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate_generator(gen(X_test, y_test, batch_size), \n",
    "                                               steps = len(X_test)/batch_size)\n",
    "print(\"Accuracy score with 4 layers:\", test_acc)\n",
    "print(\"Loss with 4 layer:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing shape of cross-validation set to make it suitable for convolutional network\n",
    "nrows, ncols = X_cv.shape\n",
    "X_cv1 = X_cv.reshape(nrows, ncols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing shape of training set to make it suitable for convolutional network\n",
    "nrows, ncols = X_train.shape\n",
    "X_train1 = X_train.reshape(nrows, ncols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing shape of test set to make it suitable for convolutional network\n",
    "nrows, ncols = X_test.shape\n",
    "X_test1 = X_test.reshape(nrows, ncols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_cv1.shape)\n",
    "print(X_train1.shape)\n",
    "print(X_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional network without hyper-parameter tuning\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, (3), input_shape=(16,1), activation='relu'))\n",
    "model.add(Conv1D(64, (3), activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(64, (3), activation='relu'))\n",
    "model.add(Conv1D(64, (3), activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(9, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.fit_generator(gen(X_train1, y_train, batch_size), \n",
    "                    steps_per_epoch = len(X_train)/batch_size, \n",
    "                    nb_epoch = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate_generator(gen(X_test1, y_test, batch_size), \n",
    "                                               steps = len(X_test)/batch_size)\n",
    "print(\"Accuracy score with ConvNet 1D:\", test_acc)\n",
    "print(\"Loss with ConvNet:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier to tune epochs and batches to be used by KerasClassifer\n",
    "def clf():\n",
    "    act1 = 'relu'\n",
    "    act2 = 'softmax'\n",
    "    opt = 'adam'\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, (3), input_shape = (16,1), activation = act1))\n",
    "    model.add(Conv1D(64, (3), activation = act1))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Conv1D(64, (3), activation = act1))\n",
    "    model.add(Conv1D(64, (3), activation = act1))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation = act1))\n",
    "    model.add(Dense(9, activation = act2))\n",
    "    model.compile(loss = 'categorical_crossentropy',optimizer = opt, metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values of epochs and batch_size to tune \n",
    "epochs = [25, 50, 75, 100]\n",
    "batch_size = [8, 32, 64, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramter grid\n",
    "param_grid = dict(batch_size = batch_size, epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = clf, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning convolutional network for epochs and batch_size\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, n_jobs = -1)\n",
    "grid_result = grid.fit(X_cv1, y_cv)\n",
    "print(\"Best score: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier to tune optimizer to be used by KerasClassifer\n",
    "def clf1(optimizer = 'adam'):\n",
    "    act1 = 'relu'\n",
    "    act2 = 'softmax'\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, (3), input_shape = (16,1), activation = act1))\n",
    "    model.add(Conv1D(64, (3), activation = act1))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Conv1D(64, (3), activation = act1))\n",
    "    model.add(Conv1D(64, (3), activation = act1))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation = act1))\n",
    "    model.add(Dense(9, activation = act2))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values of optimizer to tune\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter grid\n",
    "param_grid = dict(optimizer = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=clf1, epochs=100, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning convolutional network for optimizer\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, n_jobs = -1)\n",
    "grid_result = grid.fit(X_cv1, y_cv)\n",
    "print(\"Best score: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier to tune learning rate to be used by KerasClassifer\n",
    "def clf2(l_rate = 0.01):\n",
    "    act1 = 'relu'\n",
    "    act2 = 'softmax'\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, (3), input_shape = (16,1), activation = act1))\n",
    "    model.add(Conv1D(64, (3), activation = act1))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Conv1D(64, (3), activation = act1))\n",
    "    model.add(Conv1D(64, (3), activation = act1))\n",
    "    model.add(MaxPooling1D(2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation = act1))\n",
    "    model.add(Dense(9, activation = act2))\n",
    "    optimizer = optimizers.Adamax(lr=l_rate)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values of learning rate to tune\n",
    "l_rate = [0.01, 0.1, 0.3, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter grid\n",
    "param_grid = dict(l_rate = l_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=clf2, epochs=100, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning convolutional network for learning rate\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, n_jobs = -1)\n",
    "grid_result = grid.fit(X_cv1, y_cv)\n",
    "print(\"Best score: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional network with best values for epochs, batch_size, optimizer and learning rate\n",
    "# after hyper-parameter tuning\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, (3), input_shape=(16,1), activation='relu'))\n",
    "model.add(Conv1D(64, (3), activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(64, (3), activation='relu'))\n",
    "model.add(Conv1D(64, (3), activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(9, activation='softmax'))\n",
    "optimizer = optimizers.Adamax(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optimizer, metrics=['accuracy'])\n",
    "model.fit_generator(gen(X_train1, y_train, 32), \n",
    "                    steps_per_epoch = len(X_train)/32, \n",
    "                    nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate_generator(gen(X_test1, y_test, 32), \n",
    "                                               steps = len(X_test)/32)\n",
    "print(\"Accuracy score with ConvNet with Hyper-parameter tuning:\", test_acc)\n",
    "print(\"Loss with ConvNet with Hyper-parameter tuning::\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
